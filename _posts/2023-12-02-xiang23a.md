---
title: Exploiting Network Compressibility and Topology in Zero-Cost NAS
openreview: y7rbX884LZrX
abstract: Neural Architecture Search (NAS) has been widely used to discover high-performance
  neural network architectures over manually designed approaches. Despite their success,
  current NAS approaches often require extensive evaluation of many candidate architectures
  in the search space or training of large super networks. To reduce the search cost,
  recently proposed zero-cost proxies are utilized to efficiently predict the performance
  of an architecture. However, while many new proxies have been proposed in recent
  years, relatively little attention has been dedicated to pushing our understanding
  of the existing ones, with their mutual effects on each other being a particularly
  – but not entirely – overlooked topic. Contrary to that trend, in our work, we argue
  that it is worth revisiting and analysing the existing proxies in order to further
  push the boundaries of zero-cost NAS. Towards that goal, we propose to view the
  existing proxies through a common lens of network compressibility, trainability,
  and expressivity, as discussed in pruning literature. Notably, doing so allows us
  to build a better understanding of the high-level relationship between different
  proxies as well as refine some of them into their more informative variants. We
  leverage these insights to design a novel saliency and metric aggregation method
  informed by compressibility, orthogonality and network topology. We show that our
  proposed methods are simple but powerful and yield some state-of-the-art results
  across popular NAS benchmarks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xiang23a
month: 0
tex_title: Exploiting Network Compressibility and Topology in Zero-Cost NAS
firstpage: 27/1
lastpage: 14
page: 27/1-14
order: 27
cycles: false
bibtex_author: Xiang, Lichuan and Hunter, Rosco and Xu, Minghao and Dudziak, {\L}ukasz
  and Wen, Hongkai
author:
- given: Lichuan
  family: Xiang
- given: Rosco
  family: Hunter
- given: Minghao
  family: Xu
- given: Łukasz
  family: Dudziak
- given: Hongkai
  family: Wen
date: 2023-12-02
address:
container-title: Proceedings of the Second International Conference on Automated Machine
  Learning
volume: '228'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v228/xiang23a/xiang23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
